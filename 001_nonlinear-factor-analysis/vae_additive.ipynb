{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIATIONAL AUTO-ENCODER\n",
    "# Fits a VAE to the data and save the fitted functions\n",
    "# Same as vae_M1 but\n",
    "# This version of vae estimates the residual variance of the observations.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "from pathlib import Path\n",
    "import scipy.stats as scs\n",
    "import argparse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a parser for the file\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"dir\", help=\"the name of the directory\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "\n",
    "# Replace this by the above in the script\n",
    "class myparser():\n",
    "    def __init__(self, dir):\n",
    "        self.dir = dir\n",
    "\n",
    "\n",
    "args = myparser(\"../simulations/M2_q5/data_p50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Create the sampling layer\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "# ## Create the variational autoencoder\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, K, known_variance, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.K = K\n",
    "        self.known_variance=known_variance\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = 0.5 * tf.reduce_mean(tf.reduce_sum((data - reconstruction)**2 / self.known_variance + tf.math.log(self.known_variance) + tf.math.log(2. * np.pi), axis=1))\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"total_loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "\n",
    "def generate_vae(input_shape, latent_dim, K=5, known_variance=1.):\n",
    "    # ## Create the encoder network\n",
    "    \"\"\" Create the encoder network; K is the dimension of the last layer. A small number helps not to overfit. This is determined by n, see the paper for references.\"\"\"\n",
    "\n",
    "    encoder_inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Flatten()(encoder_inputs)\n",
    "    x = tf.keras.layers.Dropout(.3)(x)\n",
    "    x = layers.Dense(100, activation=\"tanh\")(x)\n",
    "\n",
    "    z_mean = layers.Dense(100, activation=\"tanh\")(x)\n",
    "    z_mean = layers.Dense(50, activation=\"tanh\")(x)\n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean\", activation=\"linear\")(z_mean)\n",
    "\n",
    "    z_log_var = layers.Dense(100, activation=\"tanh\")(x)\n",
    "    z_log_var = layers.Dense(50, activation=\"tanh\")(z_log_var)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\", activation=\"linear\")(z_log_var)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "    encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "    # ## Create the Decoder network\n",
    "    # For each of the latent variables, we create a NN. The last layer takes their sum.\n",
    "    x_output_list = []\n",
    "    latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "    # now split\n",
    "    latent_split = layers.Lambda(lambda x: tf.split(x, x.shape[1], axis=1))(latent_inputs)\n",
    "    for i in range(latent_dim):\n",
    "        x = layers.Dense(100, activation=\"tanh\")(latent_split[i])\n",
    "\n",
    "        x_output = layers.Dense(100, activation=\"tanh\")(x)\n",
    "        x_output = layers.Dense(50, activation=\"tanh\")(x_output)\n",
    "        x_output = layers.Dense(K, activation=\"tanh\")(x_output)\n",
    "        x_output = layers.Dense(input_shape[0], activation=\"linear\")(x_output)\n",
    "        x_output = layers.Reshape(input_shape)(x_output)\n",
    "        x_output_list.append(x_output)\n",
    "\n",
    "    x_output = layers.Add(name=\"list_of_g\")(x_output_list)\n",
    "    decoder = keras.Model(latent_inputs, x_output, name=\"decoder\")\n",
    "\n",
    "    vae = VAE(encoder, decoder, K=K, known_variance=known_variance)\n",
    "\n",
    "    return(vae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(path):\n",
    "    # we pre-train the vae by randomizing the column orders\n",
    "    data = pd.read_csv(path)\n",
    "    data = np.array(data, dtype='float32')\n",
    "    data = data[:,np.random.choice(data.shape[1], data.shape[1], replace=False)]\n",
    "    data = np.expand_dims(data, axis=-1)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_fit(data, K=5, known_variance=1., latent_dim=5):\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='total_loss', patience=50)\n",
    "    vae = generate_vae(input_shape=data.shape[1:], latent_dim=latent_dim, K=K, known_variance=known_variance)\n",
    "    vae.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001))\n",
    "    vae.fit(data, epochs=1000, callbacks=[callback])\n",
    "\n",
    "    # We now create a model to give as output the `latent_dim` functions evaluated for a given $z$.\n",
    "\n",
    "    intermediate_layer_model = keras.Model(inputs = vae.decoder.input,\n",
    "                                        outputs = vae.decoder.get_layer(\"list_of_g\").input)\n",
    "\n",
    "    return(vae, intermediate_layer_model)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the estimated decoder functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_output(data, vae, intermediate_model, file):\n",
    "\n",
    "    # save g\n",
    "    dist = scs.norm(0,1)\n",
    "    prob = np.arange(1,201)/201.\n",
    "    z = dist.ppf(prob)\n",
    "    z = np.repeat(z[:, np.newaxis], num_latent, axis=1)\n",
    "\n",
    "    y_list = intermediate_model.predict(z)\n",
    "\n",
    "    for k in range(len(y_list)):\n",
    "        y = y_list[k].squeeze()\n",
    "        zy = np.concatenate((z[:,0, np.newaxis], y), axis=1)\n",
    "        df = pd.DataFrame(\n",
    "            data=zy, \n",
    "            columns=[\"z\"] + [\"g\"+str(i+1) for i in range(y.shape[1])])\n",
    "\n",
    "        # create folder\n",
    "        outdir = PATH_TO_FIT/f\"g{(k+1)}\"\n",
    "        outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # save\n",
    "        df.to_csv(outdir/file, index=False)\n",
    "\n",
    "    # save z\n",
    "\n",
    "    z, _, _ = vae.encoder(data)\n",
    "    df = pd.DataFrame(\n",
    "        data = z,\n",
    "        columns = [\"z\" + str(i+1) for i in range(z.shape[1])]\n",
    "    )\n",
    "    # create folder\n",
    "    outdir = PATH_TO_FIT/\"z\"\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # save\n",
    "    df.to_csv(outdir/file, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100 files found in  directory ../simulations/M2_q5/data_p50.\n",
      "Epoch 1/1000\n",
      "7/7 [==============================] - 6s 5ms/step - total_loss: 157.6211 - reconstruction_loss: 155.9619 - kl_loss: 1.6593\n",
      "Epoch 2/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 152.8999 - reconstruction_loss: 151.3876 - kl_loss: 1.5123\n",
      "Epoch 3/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 147.3224 - reconstruction_loss: 145.5430 - kl_loss: 1.7793\n",
      "Epoch 4/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 143.6384 - reconstruction_loss: 141.6662 - kl_loss: 1.9722\n",
      "Epoch 5/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 139.9666 - reconstruction_loss: 137.8372 - kl_loss: 2.1294\n",
      "Epoch 6/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 138.7605 - reconstruction_loss: 136.4330 - kl_loss: 2.3275\n",
      "Epoch 7/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 136.4921 - reconstruction_loss: 133.9642 - kl_loss: 2.5280\n",
      "Epoch 8/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 135.6247 - reconstruction_loss: 132.9866 - kl_loss: 2.6381\n",
      "Epoch 9/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 132.4670 - reconstruction_loss: 129.5908 - kl_loss: 2.8761\n",
      "Epoch 10/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 132.7551 - reconstruction_loss: 129.7966 - kl_loss: 2.9585\n",
      "Epoch 11/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 131.5620 - reconstruction_loss: 128.5379 - kl_loss: 3.0241\n",
      "Epoch 12/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 131.4704 - reconstruction_loss: 128.2776 - kl_loss: 3.1928\n",
      "Epoch 13/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 129.9342 - reconstruction_loss: 126.5981 - kl_loss: 3.3361\n",
      "Epoch 14/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 129.9051 - reconstruction_loss: 126.5911 - kl_loss: 3.3140\n",
      "Epoch 15/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 129.9853 - reconstruction_loss: 126.5890 - kl_loss: 3.3962\n",
      "Epoch 16/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 129.2440 - reconstruction_loss: 125.6824 - kl_loss: 3.5617\n",
      "Epoch 17/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 127.6040 - reconstruction_loss: 123.8542 - kl_loss: 3.7498\n",
      "Epoch 18/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 127.9666 - reconstruction_loss: 124.4171 - kl_loss: 3.5495\n",
      "Epoch 19/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 128.4312 - reconstruction_loss: 125.0047 - kl_loss: 3.4265\n",
      "Epoch 20/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 128.0195 - reconstruction_loss: 124.3161 - kl_loss: 3.7033\n",
      "Epoch 21/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 127.5723 - reconstruction_loss: 123.7178 - kl_loss: 3.8544\n",
      "Epoch 22/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 127.4639 - reconstruction_loss: 123.4693 - kl_loss: 3.9946\n",
      "Epoch 23/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 127.0747 - reconstruction_loss: 122.9629 - kl_loss: 4.1119\n",
      "Epoch 24/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 125.6802 - reconstruction_loss: 121.5379 - kl_loss: 4.1422\n",
      "Epoch 25/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 126.0301 - reconstruction_loss: 121.9189 - kl_loss: 4.1112\n",
      "Epoch 26/1000\n",
      "7/7 [==============================] - 0s 11ms/step - total_loss: 126.2057 - reconstruction_loss: 121.9796 - kl_loss: 4.2261\n",
      "Epoch 27/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 125.4712 - reconstruction_loss: 121.1594 - kl_loss: 4.3118\n",
      "Epoch 28/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 126.2495 - reconstruction_loss: 122.0724 - kl_loss: 4.1771\n",
      "Epoch 29/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 125.9405 - reconstruction_loss: 121.6314 - kl_loss: 4.3091\n",
      "Epoch 30/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 125.2810 - reconstruction_loss: 120.6458 - kl_loss: 4.6353\n",
      "Epoch 31/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 125.4126 - reconstruction_loss: 120.9197 - kl_loss: 4.4929\n",
      "Epoch 32/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 124.0551 - reconstruction_loss: 119.5927 - kl_loss: 4.4624\n",
      "Epoch 33/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 125.0466 - reconstruction_loss: 120.4943 - kl_loss: 4.5524\n",
      "Epoch 34/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 124.8752 - reconstruction_loss: 120.2603 - kl_loss: 4.6149\n",
      "Epoch 35/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 124.0036 - reconstruction_loss: 119.3406 - kl_loss: 4.6631\n",
      "Epoch 36/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 123.6404 - reconstruction_loss: 119.0443 - kl_loss: 4.5960\n",
      "Epoch 37/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 124.0225 - reconstruction_loss: 119.4982 - kl_loss: 4.5242\n",
      "Epoch 38/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 122.6581 - reconstruction_loss: 118.0869 - kl_loss: 4.5712\n",
      "Epoch 39/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 122.7664 - reconstruction_loss: 118.1103 - kl_loss: 4.6561\n",
      "Epoch 40/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 122.7380 - reconstruction_loss: 117.9387 - kl_loss: 4.7993\n",
      "Epoch 41/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 123.1269 - reconstruction_loss: 118.4147 - kl_loss: 4.7122\n",
      "Epoch 42/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 122.8709 - reconstruction_loss: 118.1685 - kl_loss: 4.7024\n",
      "Epoch 43/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 122.6163 - reconstruction_loss: 117.7694 - kl_loss: 4.8469\n",
      "Epoch 44/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 122.3233 - reconstruction_loss: 117.4263 - kl_loss: 4.8970\n",
      "Epoch 45/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 123.4826 - reconstruction_loss: 118.4811 - kl_loss: 5.0015\n",
      "Epoch 46/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 121.9344 - reconstruction_loss: 116.8879 - kl_loss: 5.0465\n",
      "Epoch 47/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 122.5523 - reconstruction_loss: 117.5613 - kl_loss: 4.9910\n",
      "Epoch 48/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 121.9203 - reconstruction_loss: 116.8905 - kl_loss: 5.0298\n",
      "Epoch 49/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 122.6162 - reconstruction_loss: 117.6971 - kl_loss: 4.9191\n",
      "Epoch 50/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 121.6038 - reconstruction_loss: 116.5920 - kl_loss: 5.0118\n",
      "Epoch 51/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 121.0356 - reconstruction_loss: 116.0334 - kl_loss: 5.0022\n",
      "Epoch 52/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 121.4346 - reconstruction_loss: 116.3726 - kl_loss: 5.0620\n",
      "Epoch 53/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 121.4536 - reconstruction_loss: 116.3864 - kl_loss: 5.0672\n",
      "Epoch 54/1000\n",
      "7/7 [==============================] - 0s 13ms/step - total_loss: 121.1008 - reconstruction_loss: 115.8619 - kl_loss: 5.2389\n",
      "Epoch 55/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 120.6468 - reconstruction_loss: 115.3097 - kl_loss: 5.3372\n",
      "Epoch 56/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 121.0472 - reconstruction_loss: 115.9021 - kl_loss: 5.1451\n",
      "Epoch 57/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 121.0727 - reconstruction_loss: 115.8227 - kl_loss: 5.2500\n",
      "Epoch 58/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 120.9233 - reconstruction_loss: 115.5664 - kl_loss: 5.3570\n",
      "Epoch 59/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 120.6527 - reconstruction_loss: 115.1700 - kl_loss: 5.4827\n",
      "Epoch 60/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 120.6708 - reconstruction_loss: 115.2826 - kl_loss: 5.3883\n",
      "Epoch 61/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 119.7681 - reconstruction_loss: 114.4868 - kl_loss: 5.2813\n",
      "Epoch 62/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 119.6889 - reconstruction_loss: 114.1769 - kl_loss: 5.5121\n",
      "Epoch 63/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 119.7017 - reconstruction_loss: 114.1218 - kl_loss: 5.5799\n",
      "Epoch 64/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 119.4702 - reconstruction_loss: 114.0305 - kl_loss: 5.4397\n",
      "Epoch 65/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 118.1367 - reconstruction_loss: 112.6708 - kl_loss: 5.4659\n",
      "Epoch 66/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 120.3274 - reconstruction_loss: 114.9423 - kl_loss: 5.3851\n",
      "Epoch 67/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 118.8372 - reconstruction_loss: 113.4146 - kl_loss: 5.4225\n",
      "Epoch 68/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 119.8765 - reconstruction_loss: 114.4314 - kl_loss: 5.4451\n",
      "Epoch 69/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 118.9814 - reconstruction_loss: 113.3979 - kl_loss: 5.5835\n",
      "Epoch 70/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 119.6533 - reconstruction_loss: 114.0379 - kl_loss: 5.6155\n",
      "Epoch 71/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 118.6130 - reconstruction_loss: 113.0160 - kl_loss: 5.5970\n",
      "Epoch 72/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 117.8571 - reconstruction_loss: 112.2275 - kl_loss: 5.6296\n",
      "Epoch 73/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 118.7795 - reconstruction_loss: 113.2128 - kl_loss: 5.5667\n",
      "Epoch 74/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 119.5126 - reconstruction_loss: 113.7611 - kl_loss: 5.7515\n",
      "Epoch 75/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 119.0712 - reconstruction_loss: 113.1372 - kl_loss: 5.9340\n",
      "Epoch 76/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 119.7417 - reconstruction_loss: 113.9152 - kl_loss: 5.8265\n",
      "Epoch 77/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 118.7504 - reconstruction_loss: 112.9697 - kl_loss: 5.7807\n",
      "Epoch 78/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 118.5399 - reconstruction_loss: 112.7670 - kl_loss: 5.7729\n",
      "Epoch 79/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 118.4907 - reconstruction_loss: 112.7524 - kl_loss: 5.7383\n",
      "Epoch 80/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 118.6745 - reconstruction_loss: 112.8178 - kl_loss: 5.8567\n",
      "Epoch 81/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 117.6899 - reconstruction_loss: 111.7223 - kl_loss: 5.9675\n",
      "Epoch 82/1000\n",
      "7/7 [==============================] - 0s 14ms/step - total_loss: 118.2702 - reconstruction_loss: 112.3708 - kl_loss: 5.8994\n",
      "Epoch 83/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 117.9339 - reconstruction_loss: 112.0592 - kl_loss: 5.8747\n",
      "Epoch 84/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 117.2819 - reconstruction_loss: 111.4220 - kl_loss: 5.8599\n",
      "Epoch 85/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 118.0961 - reconstruction_loss: 112.1368 - kl_loss: 5.9593\n",
      "Epoch 86/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 118.0004 - reconstruction_loss: 112.1034 - kl_loss: 5.8970\n",
      "Epoch 87/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 117.3895 - reconstruction_loss: 111.4250 - kl_loss: 5.9645\n",
      "Epoch 88/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 118.3035 - reconstruction_loss: 112.4073 - kl_loss: 5.8962\n",
      "Epoch 89/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 118.0006 - reconstruction_loss: 112.2757 - kl_loss: 5.7249\n",
      "Epoch 90/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 117.0452 - reconstruction_loss: 111.2205 - kl_loss: 5.8246\n",
      "Epoch 91/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 117.1798 - reconstruction_loss: 111.3410 - kl_loss: 5.8388\n",
      "Epoch 92/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 117.6777 - reconstruction_loss: 111.7044 - kl_loss: 5.9733\n",
      "Epoch 93/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 117.3929 - reconstruction_loss: 111.2303 - kl_loss: 6.1626\n",
      "Epoch 94/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 116.1975 - reconstruction_loss: 110.0499 - kl_loss: 6.1475\n",
      "Epoch 95/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 117.2629 - reconstruction_loss: 110.9435 - kl_loss: 6.3194\n",
      "Epoch 96/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 117.3201 - reconstruction_loss: 111.2634 - kl_loss: 6.0567\n",
      "Epoch 97/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 117.1004 - reconstruction_loss: 111.1490 - kl_loss: 5.9514\n",
      "Epoch 98/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 115.9187 - reconstruction_loss: 109.8549 - kl_loss: 6.0638\n",
      "Epoch 99/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 117.4317 - reconstruction_loss: 111.3501 - kl_loss: 6.0815\n",
      "Epoch 100/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 117.0392 - reconstruction_loss: 110.9439 - kl_loss: 6.0953\n",
      "Epoch 101/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 116.7509 - reconstruction_loss: 110.4373 - kl_loss: 6.3136\n",
      "Epoch 102/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 117.2837 - reconstruction_loss: 110.9370 - kl_loss: 6.3467\n",
      "Epoch 103/1000\n",
      "7/7 [==============================] - 0s 8ms/step - total_loss: 116.6993 - reconstruction_loss: 110.4925 - kl_loss: 6.2068\n",
      "Epoch 104/1000\n",
      "7/7 [==============================] - 0s 12ms/step - total_loss: 116.1914 - reconstruction_loss: 110.0285 - kl_loss: 6.1628\n",
      "Epoch 105/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 116.4453 - reconstruction_loss: 110.4284 - kl_loss: 6.0169\n",
      "Epoch 106/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 116.6367 - reconstruction_loss: 110.5937 - kl_loss: 6.0430\n",
      "Epoch 107/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 116.5178 - reconstruction_loss: 110.5454 - kl_loss: 5.9725\n",
      "Epoch 108/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 117.0118 - reconstruction_loss: 111.0473 - kl_loss: 5.9644\n",
      "Epoch 109/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 117.2191 - reconstruction_loss: 111.2230 - kl_loss: 5.9961\n",
      "Epoch 110/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 116.7076 - reconstruction_loss: 110.5348 - kl_loss: 6.1728\n",
      "Epoch 111/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 116.2420 - reconstruction_loss: 109.9507 - kl_loss: 6.2914\n",
      "Epoch 112/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 116.2512 - reconstruction_loss: 109.9471 - kl_loss: 6.3041\n",
      "Epoch 113/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 116.7808 - reconstruction_loss: 110.3226 - kl_loss: 6.4582\n",
      "Epoch 114/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 116.6564 - reconstruction_loss: 110.1690 - kl_loss: 6.4874\n",
      "Epoch 115/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 116.0932 - reconstruction_loss: 109.6559 - kl_loss: 6.4373\n",
      "Epoch 116/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 116.7075 - reconstruction_loss: 110.3147 - kl_loss: 6.3928\n",
      "Epoch 117/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 115.2642 - reconstruction_loss: 108.8995 - kl_loss: 6.3647\n",
      "Epoch 118/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 117.5413 - reconstruction_loss: 111.1522 - kl_loss: 6.3891\n",
      "Epoch 119/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 115.9509 - reconstruction_loss: 109.5274 - kl_loss: 6.4235\n",
      "Epoch 120/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 115.9835 - reconstruction_loss: 109.4665 - kl_loss: 6.5169\n",
      "Epoch 121/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 116.3138 - reconstruction_loss: 109.6349 - kl_loss: 6.6789\n",
      "Epoch 122/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 115.4457 - reconstruction_loss: 108.9579 - kl_loss: 6.4877\n",
      "Epoch 123/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 115.9093 - reconstruction_loss: 109.4979 - kl_loss: 6.4114\n",
      "Epoch 124/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 115.6635 - reconstruction_loss: 109.2924 - kl_loss: 6.3711\n",
      "Epoch 125/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 116.4558 - reconstruction_loss: 109.8716 - kl_loss: 6.5841\n",
      "Epoch 126/1000\n",
      "7/7 [==============================] - 0s 8ms/step - total_loss: 115.1937 - reconstruction_loss: 108.5465 - kl_loss: 6.6472\n",
      "Epoch 127/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 116.8605 - reconstruction_loss: 110.1786 - kl_loss: 6.6819\n",
      "Epoch 128/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 116.4612 - reconstruction_loss: 109.7293 - kl_loss: 6.7319\n",
      "Epoch 129/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 116.0788 - reconstruction_loss: 109.4930 - kl_loss: 6.5858\n",
      "Epoch 130/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 116.4067 - reconstruction_loss: 110.1265 - kl_loss: 6.2801\n",
      "Epoch 131/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 114.8856 - reconstruction_loss: 108.6631 - kl_loss: 6.2224\n",
      "Epoch 132/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 115.8015 - reconstruction_loss: 109.6041 - kl_loss: 6.1974\n",
      "Epoch 133/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 116.5250 - reconstruction_loss: 110.2047 - kl_loss: 6.3203\n",
      "Epoch 134/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 116.1885 - reconstruction_loss: 109.8084 - kl_loss: 6.3801\n",
      "Epoch 135/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 115.1896 - reconstruction_loss: 108.6117 - kl_loss: 6.5778\n",
      "Epoch 136/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 116.3445 - reconstruction_loss: 109.7184 - kl_loss: 6.6261\n",
      "Epoch 137/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 114.9247 - reconstruction_loss: 108.2038 - kl_loss: 6.7209\n",
      "Epoch 138/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 115.3614 - reconstruction_loss: 108.6726 - kl_loss: 6.6889\n",
      "Epoch 139/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 115.2692 - reconstruction_loss: 108.6978 - kl_loss: 6.5714\n",
      "Epoch 140/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 114.9637 - reconstruction_loss: 108.3273 - kl_loss: 6.6364\n",
      "Epoch 141/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 115.0196 - reconstruction_loss: 108.2075 - kl_loss: 6.8121\n",
      "Epoch 142/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 114.8326 - reconstruction_loss: 107.9464 - kl_loss: 6.8862\n",
      "Epoch 143/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 114.2311 - reconstruction_loss: 107.3505 - kl_loss: 6.8806\n",
      "Epoch 144/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 115.3941 - reconstruction_loss: 108.6542 - kl_loss: 6.7398\n",
      "Epoch 145/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 115.1028 - reconstruction_loss: 108.5551 - kl_loss: 6.5477\n",
      "Epoch 146/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 114.7193 - reconstruction_loss: 108.1879 - kl_loss: 6.5314\n",
      "Epoch 147/1000\n",
      "7/7 [==============================] - 0s 11ms/step - total_loss: 115.3674 - reconstruction_loss: 108.8492 - kl_loss: 6.5181\n",
      "Epoch 148/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 115.3249 - reconstruction_loss: 108.5329 - kl_loss: 6.7921\n",
      "Epoch 149/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 113.7299 - reconstruction_loss: 106.9636 - kl_loss: 6.7662\n",
      "Epoch 150/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 114.5441 - reconstruction_loss: 107.8142 - kl_loss: 6.7299\n",
      "Epoch 151/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 114.7514 - reconstruction_loss: 108.1299 - kl_loss: 6.6216\n",
      "Epoch 152/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 114.5219 - reconstruction_loss: 107.9336 - kl_loss: 6.5883\n",
      "Epoch 153/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 114.3408 - reconstruction_loss: 107.6473 - kl_loss: 6.6935\n",
      "Epoch 154/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 115.0888 - reconstruction_loss: 108.2616 - kl_loss: 6.8272\n",
      "Epoch 155/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 114.4292 - reconstruction_loss: 107.6612 - kl_loss: 6.7679\n",
      "Epoch 156/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 114.7497 - reconstruction_loss: 108.0123 - kl_loss: 6.7374\n",
      "Epoch 157/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 113.9331 - reconstruction_loss: 107.2343 - kl_loss: 6.6988\n",
      "Epoch 158/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 114.9777 - reconstruction_loss: 108.1821 - kl_loss: 6.7957\n",
      "Epoch 159/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 113.9744 - reconstruction_loss: 107.1989 - kl_loss: 6.7755\n",
      "Epoch 160/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 114.5936 - reconstruction_loss: 107.6822 - kl_loss: 6.9114\n",
      "Epoch 161/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 114.5972 - reconstruction_loss: 107.5850 - kl_loss: 7.0123\n",
      "Epoch 162/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 114.5063 - reconstruction_loss: 107.5262 - kl_loss: 6.9801\n",
      "Epoch 163/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 114.2480 - reconstruction_loss: 107.2144 - kl_loss: 7.0336\n",
      "Epoch 164/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 114.7098 - reconstruction_loss: 107.8274 - kl_loss: 6.8824\n",
      "Epoch 165/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 114.6263 - reconstruction_loss: 107.7826 - kl_loss: 6.8437\n",
      "Epoch 166/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 113.6184 - reconstruction_loss: 106.7871 - kl_loss: 6.8314\n",
      "Epoch 167/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 114.3204 - reconstruction_loss: 107.3761 - kl_loss: 6.9443\n",
      "Epoch 168/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 113.7964 - reconstruction_loss: 106.8101 - kl_loss: 6.9863\n",
      "Epoch 169/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 114.1995 - reconstruction_loss: 107.3527 - kl_loss: 6.8469\n",
      "Epoch 170/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 113.7841 - reconstruction_loss: 106.9885 - kl_loss: 6.7956\n",
      "Epoch 171/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 114.1130 - reconstruction_loss: 107.4181 - kl_loss: 6.6949\n",
      "Epoch 172/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 114.0150 - reconstruction_loss: 107.3176 - kl_loss: 6.6974\n",
      "Epoch 173/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 113.4252 - reconstruction_loss: 106.6224 - kl_loss: 6.8028\n",
      "Epoch 174/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 113.5874 - reconstruction_loss: 106.7916 - kl_loss: 6.7958\n",
      "Epoch 175/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 113.4435 - reconstruction_loss: 106.5741 - kl_loss: 6.8694\n",
      "Epoch 176/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 113.4641 - reconstruction_loss: 106.5206 - kl_loss: 6.9434\n",
      "Epoch 177/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 113.8856 - reconstruction_loss: 106.7844 - kl_loss: 7.1012\n",
      "Epoch 178/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 114.0652 - reconstruction_loss: 106.9847 - kl_loss: 7.0806\n",
      "Epoch 179/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 113.0756 - reconstruction_loss: 106.1542 - kl_loss: 6.9214\n",
      "Epoch 180/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 113.5106 - reconstruction_loss: 106.5836 - kl_loss: 6.9270\n",
      "Epoch 181/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 114.5359 - reconstruction_loss: 107.5764 - kl_loss: 6.9595\n",
      "Epoch 182/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 114.4878 - reconstruction_loss: 107.4508 - kl_loss: 7.0370\n",
      "Epoch 183/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 114.2538 - reconstruction_loss: 107.1361 - kl_loss: 7.1177\n",
      "Epoch 184/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 114.0367 - reconstruction_loss: 106.7787 - kl_loss: 7.2581\n",
      "Epoch 185/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 112.9072 - reconstruction_loss: 105.6935 - kl_loss: 7.2137\n",
      "Epoch 186/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 114.3502 - reconstruction_loss: 107.2205 - kl_loss: 7.1297\n",
      "Epoch 187/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 113.7689 - reconstruction_loss: 106.6417 - kl_loss: 7.1273\n",
      "Epoch 188/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 112.9662 - reconstruction_loss: 105.9354 - kl_loss: 7.0308\n",
      "Epoch 189/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 114.1909 - reconstruction_loss: 107.1390 - kl_loss: 7.0519\n",
      "Epoch 190/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 114.2277 - reconstruction_loss: 107.0963 - kl_loss: 7.1314\n",
      "Epoch 191/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 113.8319 - reconstruction_loss: 106.6586 - kl_loss: 7.1733\n",
      "Epoch 192/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 113.5806 - reconstruction_loss: 106.5619 - kl_loss: 7.0188\n",
      "Epoch 193/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 112.9543 - reconstruction_loss: 105.9344 - kl_loss: 7.0199\n",
      "Epoch 194/1000\n",
      "7/7 [==============================] - 0s 12ms/step - total_loss: 114.3103 - reconstruction_loss: 107.1733 - kl_loss: 7.1370\n",
      "Epoch 195/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 113.4926 - reconstruction_loss: 106.3551 - kl_loss: 7.1375\n",
      "Epoch 196/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 113.3770 - reconstruction_loss: 106.1182 - kl_loss: 7.2588\n",
      "Epoch 197/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 112.4174 - reconstruction_loss: 105.2994 - kl_loss: 7.1180\n",
      "Epoch 198/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 113.1973 - reconstruction_loss: 106.1239 - kl_loss: 7.0734\n",
      "Epoch 199/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 113.8204 - reconstruction_loss: 106.7078 - kl_loss: 7.1126\n",
      "Epoch 200/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 113.5387 - reconstruction_loss: 106.3848 - kl_loss: 7.1539\n",
      "Epoch 201/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 113.3190 - reconstruction_loss: 106.0436 - kl_loss: 7.2755\n",
      "Epoch 202/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 113.2071 - reconstruction_loss: 106.0009 - kl_loss: 7.2062\n",
      "Epoch 203/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 112.2544 - reconstruction_loss: 105.2799 - kl_loss: 6.9745\n",
      "Epoch 204/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 113.1059 - reconstruction_loss: 106.0728 - kl_loss: 7.0331\n",
      "Epoch 205/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 113.1257 - reconstruction_loss: 105.8047 - kl_loss: 7.3210\n",
      "Epoch 206/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 111.9226 - reconstruction_loss: 104.6863 - kl_loss: 7.2363\n",
      "Epoch 207/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 111.9158 - reconstruction_loss: 104.6766 - kl_loss: 7.2393\n",
      "Epoch 208/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 112.8052 - reconstruction_loss: 105.5942 - kl_loss: 7.2109\n",
      "Epoch 209/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 112.8233 - reconstruction_loss: 105.5063 - kl_loss: 7.3170\n",
      "Epoch 210/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 112.2787 - reconstruction_loss: 105.0139 - kl_loss: 7.2648\n",
      "Epoch 211/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 113.2887 - reconstruction_loss: 106.1044 - kl_loss: 7.1842\n",
      "Epoch 212/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 111.8098 - reconstruction_loss: 104.7360 - kl_loss: 7.0737\n",
      "Epoch 213/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 111.9628 - reconstruction_loss: 105.0415 - kl_loss: 6.9213\n",
      "Epoch 214/1000\n",
      "7/7 [==============================] - 0s 12ms/step - total_loss: 112.1305 - reconstruction_loss: 105.1219 - kl_loss: 7.0086\n",
      "Epoch 215/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 112.9735 - reconstruction_loss: 105.7971 - kl_loss: 7.1763\n",
      "Epoch 216/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 113.0613 - reconstruction_loss: 105.6715 - kl_loss: 7.3899\n",
      "Epoch 217/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 112.3377 - reconstruction_loss: 104.5735 - kl_loss: 7.7642\n",
      "Epoch 218/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 112.6819 - reconstruction_loss: 105.1164 - kl_loss: 7.5654\n",
      "Epoch 219/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 113.2433 - reconstruction_loss: 105.9772 - kl_loss: 7.2662\n",
      "Epoch 220/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 111.3602 - reconstruction_loss: 104.1726 - kl_loss: 7.1877\n",
      "Epoch 221/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 111.4862 - reconstruction_loss: 104.2522 - kl_loss: 7.2339\n",
      "Epoch 222/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 112.5477 - reconstruction_loss: 105.2161 - kl_loss: 7.3316\n",
      "Epoch 223/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 113.2131 - reconstruction_loss: 105.7330 - kl_loss: 7.4802\n",
      "Epoch 224/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 112.1073 - reconstruction_loss: 104.5303 - kl_loss: 7.5770\n",
      "Epoch 225/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 112.2375 - reconstruction_loss: 104.7559 - kl_loss: 7.4816\n",
      "Epoch 226/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 111.6096 - reconstruction_loss: 104.2015 - kl_loss: 7.4081\n",
      "Epoch 227/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 111.9272 - reconstruction_loss: 104.6059 - kl_loss: 7.3213\n",
      "Epoch 228/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 112.4722 - reconstruction_loss: 105.2894 - kl_loss: 7.1827\n",
      "Epoch 229/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 112.5585 - reconstruction_loss: 105.3519 - kl_loss: 7.2066\n",
      "Epoch 230/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 112.3622 - reconstruction_loss: 105.0225 - kl_loss: 7.3397\n",
      "Epoch 231/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 112.2172 - reconstruction_loss: 104.7763 - kl_loss: 7.4409\n",
      "Epoch 232/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 112.5740 - reconstruction_loss: 105.0979 - kl_loss: 7.4761\n",
      "Epoch 233/1000\n",
      "7/7 [==============================] - 0s 12ms/step - total_loss: 111.9952 - reconstruction_loss: 104.2408 - kl_loss: 7.7544\n",
      "Epoch 234/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 111.6247 - reconstruction_loss: 103.9060 - kl_loss: 7.7187\n",
      "Epoch 235/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 111.9907 - reconstruction_loss: 104.3617 - kl_loss: 7.6291\n",
      "Epoch 236/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 112.7757 - reconstruction_loss: 105.2434 - kl_loss: 7.5322\n",
      "Epoch 237/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 112.4914 - reconstruction_loss: 104.9599 - kl_loss: 7.5315\n",
      "Epoch 238/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 112.6043 - reconstruction_loss: 104.9343 - kl_loss: 7.6700\n",
      "Epoch 239/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 112.0297 - reconstruction_loss: 104.1750 - kl_loss: 7.8548\n",
      "Epoch 240/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 111.4390 - reconstruction_loss: 103.6850 - kl_loss: 7.7540\n",
      "Epoch 241/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 111.7019 - reconstruction_loss: 104.1583 - kl_loss: 7.5436\n",
      "Epoch 242/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 112.2219 - reconstruction_loss: 104.7753 - kl_loss: 7.4467\n",
      "Epoch 243/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 111.3038 - reconstruction_loss: 103.9193 - kl_loss: 7.3845\n",
      "Epoch 244/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 111.9029 - reconstruction_loss: 104.4357 - kl_loss: 7.4672\n",
      "Epoch 245/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 112.0938 - reconstruction_loss: 104.5493 - kl_loss: 7.5445\n",
      "Epoch 246/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 112.2083 - reconstruction_loss: 104.6230 - kl_loss: 7.5852\n",
      "Epoch 247/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 111.7542 - reconstruction_loss: 104.1195 - kl_loss: 7.6346\n",
      "Epoch 248/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 111.3865 - reconstruction_loss: 103.7976 - kl_loss: 7.5888\n",
      "Epoch 249/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 111.0945 - reconstruction_loss: 103.5226 - kl_loss: 7.5719\n",
      "Epoch 250/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 111.5129 - reconstruction_loss: 103.9826 - kl_loss: 7.5303\n",
      "Epoch 251/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 111.7153 - reconstruction_loss: 104.1010 - kl_loss: 7.6143\n",
      "Epoch 252/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 111.5063 - reconstruction_loss: 103.9218 - kl_loss: 7.5845\n",
      "Epoch 253/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 112.5523 - reconstruction_loss: 105.0062 - kl_loss: 7.5462\n",
      "Epoch 254/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 110.9222 - reconstruction_loss: 103.5154 - kl_loss: 7.4068\n",
      "Epoch 255/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 111.4563 - reconstruction_loss: 103.9553 - kl_loss: 7.5010\n",
      "Epoch 256/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 110.6498 - reconstruction_loss: 103.0920 - kl_loss: 7.5578\n",
      "Epoch 257/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 111.6251 - reconstruction_loss: 104.0235 - kl_loss: 7.6016\n",
      "Epoch 258/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 111.2447 - reconstruction_loss: 103.5771 - kl_loss: 7.6675\n",
      "Epoch 259/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.9256 - reconstruction_loss: 103.2188 - kl_loss: 7.7068\n",
      "Epoch 260/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 110.3722 - reconstruction_loss: 102.6668 - kl_loss: 7.7053\n",
      "Epoch 261/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 111.1294 - reconstruction_loss: 103.4830 - kl_loss: 7.6464\n",
      "Epoch 262/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 111.7105 - reconstruction_loss: 104.1207 - kl_loss: 7.5898\n",
      "Epoch 263/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 111.2154 - reconstruction_loss: 103.6442 - kl_loss: 7.5712\n",
      "Epoch 264/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 111.4547 - reconstruction_loss: 103.7662 - kl_loss: 7.6885\n",
      "Epoch 265/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 111.7447 - reconstruction_loss: 103.9512 - kl_loss: 7.7935\n",
      "Epoch 266/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 110.6304 - reconstruction_loss: 102.7206 - kl_loss: 7.9098\n",
      "Epoch 267/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 111.3624 - reconstruction_loss: 103.5137 - kl_loss: 7.8487\n",
      "Epoch 268/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 110.6036 - reconstruction_loss: 102.7490 - kl_loss: 7.8546\n",
      "Epoch 269/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 111.9632 - reconstruction_loss: 104.0392 - kl_loss: 7.9240\n",
      "Epoch 270/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 111.6585 - reconstruction_loss: 103.7593 - kl_loss: 7.8992\n",
      "Epoch 271/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 110.6339 - reconstruction_loss: 102.5463 - kl_loss: 8.0875\n",
      "Epoch 272/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 110.4746 - reconstruction_loss: 102.5388 - kl_loss: 7.9358\n",
      "Epoch 273/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.7291 - reconstruction_loss: 102.8543 - kl_loss: 7.8748\n",
      "Epoch 274/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 110.7821 - reconstruction_loss: 102.9056 - kl_loss: 7.8766\n",
      "Epoch 275/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 110.3327 - reconstruction_loss: 102.4574 - kl_loss: 7.8753\n",
      "Epoch 276/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 111.1930 - reconstruction_loss: 103.4441 - kl_loss: 7.7489\n",
      "Epoch 277/1000\n",
      "7/7 [==============================] - 0s 10ms/step - total_loss: 110.6462 - reconstruction_loss: 102.9205 - kl_loss: 7.7257\n",
      "Epoch 278/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.3318 - reconstruction_loss: 102.5282 - kl_loss: 7.8036\n",
      "Epoch 279/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 111.2647 - reconstruction_loss: 103.2722 - kl_loss: 7.9925\n",
      "Epoch 280/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.8968 - reconstruction_loss: 102.8292 - kl_loss: 8.0677\n",
      "Epoch 281/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.6876 - reconstruction_loss: 102.4942 - kl_loss: 8.1933\n",
      "Epoch 282/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.8616 - reconstruction_loss: 102.0085 - kl_loss: 7.8531\n",
      "Epoch 283/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 110.7322 - reconstruction_loss: 102.9521 - kl_loss: 7.7801\n",
      "Epoch 284/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.8300 - reconstruction_loss: 103.1163 - kl_loss: 7.7137\n",
      "Epoch 285/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 111.1626 - reconstruction_loss: 103.3056 - kl_loss: 7.8570\n",
      "Epoch 286/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 109.8002 - reconstruction_loss: 102.0461 - kl_loss: 7.7541\n",
      "Epoch 287/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 111.5049 - reconstruction_loss: 103.8421 - kl_loss: 7.6627\n",
      "Epoch 288/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.9186 - reconstruction_loss: 102.2269 - kl_loss: 7.6917\n",
      "Epoch 289/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.8793 - reconstruction_loss: 102.9397 - kl_loss: 7.9396\n",
      "Epoch 290/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.2529 - reconstruction_loss: 102.3311 - kl_loss: 7.9218\n",
      "Epoch 291/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 111.3538 - reconstruction_loss: 103.4581 - kl_loss: 7.8957\n",
      "Epoch 292/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.1083 - reconstruction_loss: 102.2183 - kl_loss: 7.8900\n",
      "Epoch 293/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.7763 - reconstruction_loss: 102.8005 - kl_loss: 7.9758\n",
      "Epoch 294/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 110.1139 - reconstruction_loss: 102.1157 - kl_loss: 7.9982\n",
      "Epoch 295/1000\n",
      "7/7 [==============================] - 0s 11ms/step - total_loss: 110.1778 - reconstruction_loss: 102.2342 - kl_loss: 7.9436\n",
      "Epoch 296/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 110.0000 - reconstruction_loss: 102.1673 - kl_loss: 7.8326\n",
      "Epoch 297/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.6074 - reconstruction_loss: 101.7135 - kl_loss: 7.8939\n",
      "Epoch 298/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.2965 - reconstruction_loss: 102.4142 - kl_loss: 7.8823\n",
      "Epoch 299/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 109.8725 - reconstruction_loss: 102.0609 - kl_loss: 7.8116\n",
      "Epoch 300/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.3900 - reconstruction_loss: 102.5708 - kl_loss: 7.8192\n",
      "Epoch 301/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.7138 - reconstruction_loss: 101.8045 - kl_loss: 7.9094\n",
      "Epoch 302/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 110.7676 - reconstruction_loss: 102.7777 - kl_loss: 7.9898\n",
      "Epoch 303/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.9159 - reconstruction_loss: 102.9191 - kl_loss: 7.9968\n",
      "Epoch 304/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.1633 - reconstruction_loss: 102.1506 - kl_loss: 8.0127\n",
      "Epoch 305/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.3477 - reconstruction_loss: 102.3322 - kl_loss: 8.0154\n",
      "Epoch 306/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 109.9844 - reconstruction_loss: 102.1169 - kl_loss: 7.8675\n",
      "Epoch 307/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.1976 - reconstruction_loss: 102.2550 - kl_loss: 7.9426\n",
      "Epoch 308/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 110.0214 - reconstruction_loss: 101.8838 - kl_loss: 8.1376\n",
      "Epoch 309/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.2998 - reconstruction_loss: 102.0825 - kl_loss: 8.2173\n",
      "Epoch 310/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 109.4170 - reconstruction_loss: 101.2476 - kl_loss: 8.1694\n",
      "Epoch 311/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.5498 - reconstruction_loss: 102.4626 - kl_loss: 8.0872\n",
      "Epoch 312/1000\n",
      "7/7 [==============================] - 0s 13ms/step - total_loss: 110.2317 - reconstruction_loss: 102.1240 - kl_loss: 8.1077\n",
      "Epoch 313/1000\n",
      "7/7 [==============================] - 0s 9ms/step - total_loss: 109.4411 - reconstruction_loss: 101.3508 - kl_loss: 8.0903\n",
      "Epoch 314/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 109.7992 - reconstruction_loss: 101.7122 - kl_loss: 8.0870\n",
      "Epoch 315/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 110.5911 - reconstruction_loss: 102.7024 - kl_loss: 7.8887\n",
      "Epoch 316/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.9895 - reconstruction_loss: 103.0002 - kl_loss: 7.9893\n",
      "Epoch 317/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 109.9623 - reconstruction_loss: 101.7489 - kl_loss: 8.2134\n",
      "Epoch 318/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.6388 - reconstruction_loss: 101.4601 - kl_loss: 8.1787\n",
      "Epoch 319/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 110.3130 - reconstruction_loss: 102.2257 - kl_loss: 8.0873\n",
      "Epoch 320/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.8435 - reconstruction_loss: 101.7327 - kl_loss: 8.1108\n",
      "Epoch 321/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.2369 - reconstruction_loss: 102.2556 - kl_loss: 7.9813\n",
      "Epoch 322/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.3254 - reconstruction_loss: 102.2989 - kl_loss: 8.0265\n",
      "Epoch 323/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.8021 - reconstruction_loss: 101.6606 - kl_loss: 8.1415\n",
      "Epoch 324/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 109.9105 - reconstruction_loss: 101.6655 - kl_loss: 8.2451\n",
      "Epoch 325/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 109.2897 - reconstruction_loss: 100.9943 - kl_loss: 8.2954\n",
      "Epoch 326/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.0915 - reconstruction_loss: 100.9881 - kl_loss: 8.1034\n",
      "Epoch 327/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.4412 - reconstruction_loss: 101.3693 - kl_loss: 8.0719\n",
      "Epoch 328/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.3231 - reconstruction_loss: 102.2457 - kl_loss: 8.0775\n",
      "Epoch 329/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.6302 - reconstruction_loss: 101.3977 - kl_loss: 8.2325\n",
      "Epoch 330/1000\n",
      "7/7 [==============================] - 0s 8ms/step - total_loss: 109.7714 - reconstruction_loss: 101.4106 - kl_loss: 8.3608\n",
      "Epoch 331/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 110.0562 - reconstruction_loss: 101.7021 - kl_loss: 8.3541\n",
      "Epoch 332/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.1753 - reconstruction_loss: 100.9610 - kl_loss: 8.2143\n",
      "Epoch 333/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.2547 - reconstruction_loss: 101.2103 - kl_loss: 8.0444\n",
      "Epoch 334/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 109.4675 - reconstruction_loss: 101.4016 - kl_loss: 8.0659\n",
      "Epoch 335/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 109.7866 - reconstruction_loss: 101.4073 - kl_loss: 8.3793\n",
      "Epoch 336/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.4396 - reconstruction_loss: 101.0776 - kl_loss: 8.3620\n",
      "Epoch 337/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.4885 - reconstruction_loss: 101.1944 - kl_loss: 8.2941\n",
      "Epoch 338/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 109.3384 - reconstruction_loss: 101.0692 - kl_loss: 8.2692\n",
      "Epoch 339/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 109.1222 - reconstruction_loss: 100.9305 - kl_loss: 8.1917\n",
      "Epoch 340/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 109.6411 - reconstruction_loss: 101.4014 - kl_loss: 8.2397\n",
      "Epoch 341/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 109.9110 - reconstruction_loss: 101.7390 - kl_loss: 8.1720\n",
      "Epoch 342/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 109.3548 - reconstruction_loss: 101.2534 - kl_loss: 8.1014\n",
      "Epoch 343/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 109.3768 - reconstruction_loss: 101.1080 - kl_loss: 8.2687\n",
      "Epoch 344/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 109.4927 - reconstruction_loss: 101.2821 - kl_loss: 8.2106\n",
      "Epoch 345/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 110.7257 - reconstruction_loss: 102.5719 - kl_loss: 8.1538\n",
      "Epoch 346/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.1856 - reconstruction_loss: 100.9548 - kl_loss: 8.2308\n",
      "Epoch 347/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 110.0312 - reconstruction_loss: 101.7513 - kl_loss: 8.2799\n",
      "Epoch 348/1000\n",
      "7/7 [==============================] - 0s 15ms/step - total_loss: 110.9681 - reconstruction_loss: 102.6600 - kl_loss: 8.3081\n",
      "Epoch 349/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 110.2281 - reconstruction_loss: 101.8571 - kl_loss: 8.3710\n",
      "Epoch 350/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 109.2431 - reconstruction_loss: 100.8990 - kl_loss: 8.3442\n",
      "Epoch 351/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 109.7596 - reconstruction_loss: 101.4063 - kl_loss: 8.3533\n",
      "Epoch 352/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 110.3587 - reconstruction_loss: 102.1192 - kl_loss: 8.2394\n",
      "Epoch 353/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.0890 - reconstruction_loss: 100.7893 - kl_loss: 8.2997\n",
      "Epoch 354/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 109.0249 - reconstruction_loss: 100.7710 - kl_loss: 8.2539\n",
      "Epoch 355/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.3663 - reconstruction_loss: 101.2196 - kl_loss: 8.1467\n",
      "Epoch 356/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.6968 - reconstruction_loss: 100.6709 - kl_loss: 8.0259\n",
      "Epoch 357/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 109.3741 - reconstruction_loss: 101.3881 - kl_loss: 7.9860\n",
      "Epoch 358/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.4565 - reconstruction_loss: 101.2643 - kl_loss: 8.1922\n",
      "Epoch 359/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 109.1485 - reconstruction_loss: 100.8183 - kl_loss: 8.3302\n",
      "Epoch 360/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 109.1965 - reconstruction_loss: 100.6983 - kl_loss: 8.4982\n",
      "Epoch 361/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.4401 - reconstruction_loss: 100.9620 - kl_loss: 8.4782\n",
      "Epoch 362/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 109.6504 - reconstruction_loss: 101.3138 - kl_loss: 8.3366\n",
      "Epoch 363/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.8180 - reconstruction_loss: 100.5909 - kl_loss: 8.2271\n",
      "Epoch 364/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 108.7591 - reconstruction_loss: 100.6741 - kl_loss: 8.0850\n",
      "Epoch 365/1000\n",
      "7/7 [==============================] - 0s 10ms/step - total_loss: 109.3667 - reconstruction_loss: 101.2005 - kl_loss: 8.1662\n",
      "Epoch 366/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.0263 - reconstruction_loss: 101.9461 - kl_loss: 8.0803\n",
      "Epoch 367/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.8722 - reconstruction_loss: 100.8445 - kl_loss: 8.0277\n",
      "Epoch 368/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 108.9372 - reconstruction_loss: 100.8211 - kl_loss: 8.1162\n",
      "Epoch 369/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 108.9072 - reconstruction_loss: 100.6912 - kl_loss: 8.2160\n",
      "Epoch 370/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 108.5490 - reconstruction_loss: 100.1889 - kl_loss: 8.3601\n",
      "Epoch 371/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 110.1077 - reconstruction_loss: 101.7440 - kl_loss: 8.3637\n",
      "Epoch 372/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.5753 - reconstruction_loss: 100.1798 - kl_loss: 8.3955\n",
      "Epoch 373/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.4020 - reconstruction_loss: 100.0956 - kl_loss: 8.3063\n",
      "Epoch 374/1000\n",
      "7/7 [==============================] - 0s 8ms/step - total_loss: 109.7662 - reconstruction_loss: 101.4642 - kl_loss: 8.3020\n",
      "Epoch 375/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 109.0125 - reconstruction_loss: 100.5991 - kl_loss: 8.4134\n",
      "Epoch 376/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.5524 - reconstruction_loss: 99.9469 - kl_loss: 8.6055\n",
      "Epoch 377/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 109.3727 - reconstruction_loss: 100.5513 - kl_loss: 8.8214\n",
      "Epoch 378/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.6376 - reconstruction_loss: 100.0323 - kl_loss: 8.6053\n",
      "Epoch 379/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.3100 - reconstruction_loss: 99.9909 - kl_loss: 8.3192\n",
      "Epoch 380/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.2567 - reconstruction_loss: 100.9736 - kl_loss: 8.2832\n",
      "Epoch 381/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 109.0159 - reconstruction_loss: 100.7471 - kl_loss: 8.2689\n",
      "Epoch 382/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.6890 - reconstruction_loss: 100.3010 - kl_loss: 8.3880\n",
      "Epoch 383/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.6428 - reconstruction_loss: 101.2625 - kl_loss: 8.3803\n",
      "Epoch 384/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.1756 - reconstruction_loss: 100.7005 - kl_loss: 8.4751\n",
      "Epoch 385/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.8037 - reconstruction_loss: 100.2189 - kl_loss: 8.5848\n",
      "Epoch 386/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.6930 - reconstruction_loss: 100.0582 - kl_loss: 8.6347\n",
      "Epoch 387/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.5397 - reconstruction_loss: 99.8690 - kl_loss: 8.6707\n",
      "Epoch 388/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 108.7722 - reconstruction_loss: 100.2654 - kl_loss: 8.5068\n",
      "Epoch 389/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.7181 - reconstruction_loss: 100.4296 - kl_loss: 8.2885\n",
      "Epoch 390/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.6150 - reconstruction_loss: 100.3300 - kl_loss: 8.2850\n",
      "Epoch 391/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.5176 - reconstruction_loss: 100.1315 - kl_loss: 8.3862\n",
      "Epoch 392/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 108.6499 - reconstruction_loss: 100.1982 - kl_loss: 8.4517\n",
      "Epoch 393/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.5870 - reconstruction_loss: 100.1379 - kl_loss: 8.4492\n",
      "Epoch 394/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.6995 - reconstruction_loss: 100.2297 - kl_loss: 8.4698\n",
      "Epoch 395/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.0485 - reconstruction_loss: 99.7239 - kl_loss: 8.3246\n",
      "Epoch 396/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.7624 - reconstruction_loss: 100.4281 - kl_loss: 8.3343\n",
      "Epoch 397/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.9893 - reconstruction_loss: 100.6186 - kl_loss: 8.3707\n",
      "Epoch 398/1000\n",
      "7/7 [==============================] - 0s 11ms/step - total_loss: 108.1667 - reconstruction_loss: 99.7386 - kl_loss: 8.4280\n",
      "Epoch 399/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 109.4377 - reconstruction_loss: 101.0010 - kl_loss: 8.4367\n",
      "Epoch 400/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 107.8493 - reconstruction_loss: 99.2440 - kl_loss: 8.6053\n",
      "Epoch 401/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.1869 - reconstruction_loss: 99.7613 - kl_loss: 8.4256\n",
      "Epoch 402/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.2961 - reconstruction_loss: 99.8278 - kl_loss: 8.4682\n",
      "Epoch 403/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 108.3196 - reconstruction_loss: 99.7379 - kl_loss: 8.5817\n",
      "Epoch 404/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.3951 - reconstruction_loss: 99.7467 - kl_loss: 8.6484\n",
      "Epoch 405/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 109.0457 - reconstruction_loss: 100.3757 - kl_loss: 8.6699\n",
      "Epoch 406/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.4916 - reconstruction_loss: 100.7033 - kl_loss: 8.7884\n",
      "Epoch 407/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 109.2516 - reconstruction_loss: 100.5334 - kl_loss: 8.7182\n",
      "Epoch 408/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.6940 - reconstruction_loss: 100.2079 - kl_loss: 8.4861\n",
      "Epoch 409/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 108.0112 - reconstruction_loss: 99.5308 - kl_loss: 8.4803\n",
      "Epoch 410/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.9502 - reconstruction_loss: 100.5832 - kl_loss: 8.3670\n",
      "Epoch 411/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.5849 - reconstruction_loss: 100.0246 - kl_loss: 8.5603\n",
      "Epoch 412/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.9563 - reconstruction_loss: 100.3720 - kl_loss: 8.5843\n",
      "Epoch 413/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.9265 - reconstruction_loss: 100.2266 - kl_loss: 8.7000\n",
      "Epoch 414/1000\n",
      "7/7 [==============================] - 0s 11ms/step - total_loss: 107.3943 - reconstruction_loss: 98.7306 - kl_loss: 8.6637\n",
      "Epoch 415/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 108.7224 - reconstruction_loss: 100.0692 - kl_loss: 8.6532\n",
      "Epoch 416/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 109.5771 - reconstruction_loss: 101.0159 - kl_loss: 8.5612\n",
      "Epoch 417/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 108.2657 - reconstruction_loss: 99.6202 - kl_loss: 8.6456\n",
      "Epoch 418/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 108.7439 - reconstruction_loss: 100.2040 - kl_loss: 8.5399\n",
      "Epoch 419/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.6246 - reconstruction_loss: 100.0869 - kl_loss: 8.5377\n",
      "Epoch 420/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.0582 - reconstruction_loss: 99.5425 - kl_loss: 8.5157\n",
      "Epoch 421/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.8290 - reconstruction_loss: 100.3228 - kl_loss: 8.5061\n",
      "Epoch 422/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.3872 - reconstruction_loss: 99.7851 - kl_loss: 8.6021\n",
      "Epoch 423/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 109.2590 - reconstruction_loss: 100.7311 - kl_loss: 8.5279\n",
      "Epoch 424/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.4048 - reconstruction_loss: 99.8424 - kl_loss: 8.5624\n",
      "Epoch 425/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 108.6889 - reconstruction_loss: 100.0608 - kl_loss: 8.6281\n",
      "Epoch 426/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.3392 - reconstruction_loss: 99.7877 - kl_loss: 8.5515\n",
      "Epoch 427/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 107.9248 - reconstruction_loss: 99.3937 - kl_loss: 8.5310\n",
      "Epoch 428/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 108.0830 - reconstruction_loss: 99.6916 - kl_loss: 8.3915\n",
      "Epoch 429/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 107.9735 - reconstruction_loss: 99.5424 - kl_loss: 8.4311\n",
      "Epoch 430/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.4320 - reconstruction_loss: 99.9800 - kl_loss: 8.4520\n",
      "Epoch 431/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.6130 - reconstruction_loss: 100.1607 - kl_loss: 8.4523\n",
      "Epoch 432/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 108.7621 - reconstruction_loss: 100.1078 - kl_loss: 8.6543\n",
      "Epoch 433/1000\n",
      "7/7 [==============================] - 0s 11ms/step - total_loss: 108.4861 - reconstruction_loss: 99.8041 - kl_loss: 8.6820\n",
      "Epoch 434/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 108.1330 - reconstruction_loss: 99.3605 - kl_loss: 8.7725\n",
      "Epoch 435/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 107.8741 - reconstruction_loss: 99.1384 - kl_loss: 8.7357\n",
      "Epoch 436/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.8676 - reconstruction_loss: 100.2542 - kl_loss: 8.6134\n",
      "Epoch 437/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 107.3994 - reconstruction_loss: 98.9444 - kl_loss: 8.4551\n",
      "Epoch 438/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.1044 - reconstruction_loss: 99.6743 - kl_loss: 8.4301\n",
      "Epoch 439/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 108.4109 - reconstruction_loss: 99.9951 - kl_loss: 8.4158\n",
      "Epoch 440/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 108.7739 - reconstruction_loss: 100.2215 - kl_loss: 8.5524\n",
      "Epoch 441/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.4156 - reconstruction_loss: 99.7565 - kl_loss: 8.6591\n",
      "Epoch 442/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.2848 - reconstruction_loss: 99.4894 - kl_loss: 8.7953\n",
      "Epoch 443/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 107.9245 - reconstruction_loss: 99.0636 - kl_loss: 8.8609\n",
      "Epoch 444/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 108.5556 - reconstruction_loss: 99.7755 - kl_loss: 8.7801\n",
      "Epoch 445/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.0883 - reconstruction_loss: 99.3644 - kl_loss: 8.7240\n",
      "Epoch 446/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.4660 - reconstruction_loss: 99.5557 - kl_loss: 8.9103\n",
      "Epoch 447/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 107.9964 - reconstruction_loss: 99.1511 - kl_loss: 8.8453\n",
      "Epoch 448/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.0488 - reconstruction_loss: 99.3444 - kl_loss: 8.7044\n",
      "Epoch 449/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 107.9469 - reconstruction_loss: 99.2612 - kl_loss: 8.6857\n",
      "Epoch 450/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 108.3551 - reconstruction_loss: 99.7472 - kl_loss: 8.6078\n",
      "Epoch 451/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 108.0886 - reconstruction_loss: 99.5576 - kl_loss: 8.5310\n",
      "Epoch 452/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 107.3290 - reconstruction_loss: 98.7639 - kl_loss: 8.5650\n",
      "Epoch 453/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 107.5071 - reconstruction_loss: 98.9120 - kl_loss: 8.5952\n",
      "Epoch 454/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 107.6872 - reconstruction_loss: 98.9949 - kl_loss: 8.6923\n",
      "Epoch 455/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.2416 - reconstruction_loss: 98.5227 - kl_loss: 8.7189\n",
      "Epoch 456/1000\n",
      "7/7 [==============================] - 0s 13ms/step - total_loss: 108.2323 - reconstruction_loss: 99.5477 - kl_loss: 8.6846\n",
      "Epoch 457/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 107.9121 - reconstruction_loss: 99.1659 - kl_loss: 8.7462\n",
      "Epoch 458/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 108.5620 - reconstruction_loss: 99.7401 - kl_loss: 8.8219\n",
      "Epoch 459/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 106.9967 - reconstruction_loss: 98.1799 - kl_loss: 8.8168\n",
      "Epoch 460/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 108.4586 - reconstruction_loss: 99.6374 - kl_loss: 8.8213\n",
      "Epoch 461/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 108.5474 - reconstruction_loss: 99.8690 - kl_loss: 8.6785\n",
      "Epoch 462/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 110.0209 - reconstruction_loss: 101.3844 - kl_loss: 8.6366\n",
      "Epoch 463/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.4422 - reconstruction_loss: 98.7404 - kl_loss: 8.7018\n",
      "Epoch 464/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 107.3226 - reconstruction_loss: 98.5926 - kl_loss: 8.7301\n",
      "Epoch 465/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 107.8282 - reconstruction_loss: 99.1930 - kl_loss: 8.6352\n",
      "Epoch 466/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 107.3764 - reconstruction_loss: 98.7091 - kl_loss: 8.6672\n",
      "Epoch 467/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.3070 - reconstruction_loss: 98.7061 - kl_loss: 8.6009\n",
      "Epoch 468/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 107.3445 - reconstruction_loss: 98.8218 - kl_loss: 8.5226\n",
      "Epoch 469/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 107.5362 - reconstruction_loss: 98.9459 - kl_loss: 8.5902\n",
      "Epoch 470/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 106.7498 - reconstruction_loss: 98.0735 - kl_loss: 8.6763\n",
      "Epoch 471/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 106.6739 - reconstruction_loss: 97.9863 - kl_loss: 8.6876\n",
      "Epoch 472/1000\n",
      "7/7 [==============================] - 0s 4ms/step - total_loss: 107.4573 - reconstruction_loss: 98.7493 - kl_loss: 8.7081\n",
      "Epoch 473/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 107.1647 - reconstruction_loss: 98.3462 - kl_loss: 8.8185\n",
      "Epoch 474/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.4160 - reconstruction_loss: 98.4675 - kl_loss: 8.9485\n",
      "Epoch 475/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 108.3039 - reconstruction_loss: 99.5033 - kl_loss: 8.8006\n",
      "Epoch 476/1000\n",
      "7/7 [==============================] - 0s 8ms/step - total_loss: 107.7616 - reconstruction_loss: 98.9885 - kl_loss: 8.7731\n",
      "Epoch 477/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 106.9872 - reconstruction_loss: 98.2351 - kl_loss: 8.7521\n",
      "Epoch 478/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 106.9132 - reconstruction_loss: 98.1342 - kl_loss: 8.7790\n",
      "Epoch 479/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 107.5169 - reconstruction_loss: 98.6396 - kl_loss: 8.8774\n",
      "Epoch 480/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 107.6586 - reconstruction_loss: 98.8614 - kl_loss: 8.7972\n",
      "Epoch 481/1000\n",
      "7/7 [==============================] - 0s 5ms/step - total_loss: 106.6804 - reconstruction_loss: 97.8748 - kl_loss: 8.8056\n",
      "Epoch 482/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.3790 - reconstruction_loss: 98.5306 - kl_loss: 8.8484\n",
      "Epoch 483/1000\n",
      "7/7 [==============================] - 0s 12ms/step - total_loss: 107.6081 - reconstruction_loss: 98.9361 - kl_loss: 8.6720\n",
      "Epoch 484/1000\n",
      "7/7 [==============================] - 0s 8ms/step - total_loss: 106.8830 - reconstruction_loss: 98.1808 - kl_loss: 8.7022\n",
      "Epoch 485/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.9130 - reconstruction_loss: 99.1578 - kl_loss: 8.7552\n",
      "Epoch 486/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 107.7967 - reconstruction_loss: 98.6747 - kl_loss: 9.1220\n",
      "Epoch 487/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.2602 - reconstruction_loss: 98.0169 - kl_loss: 9.2433\n",
      "Epoch 488/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.6800 - reconstruction_loss: 98.5892 - kl_loss: 9.0908\n",
      "Epoch 489/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 108.0727 - reconstruction_loss: 99.1415 - kl_loss: 8.9312\n",
      "Epoch 490/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.7630 - reconstruction_loss: 98.9175 - kl_loss: 8.8454\n",
      "Epoch 491/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 107.6978 - reconstruction_loss: 98.9254 - kl_loss: 8.7724\n",
      "Epoch 492/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 108.4867 - reconstruction_loss: 99.6132 - kl_loss: 8.8735\n",
      "Epoch 493/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.3871 - reconstruction_loss: 98.4997 - kl_loss: 8.8875\n",
      "Epoch 494/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.7394 - reconstruction_loss: 98.9614 - kl_loss: 8.7779\n",
      "Epoch 495/1000\n",
      "7/7 [==============================] - 0s 9ms/step - total_loss: 108.4161 - reconstruction_loss: 99.7410 - kl_loss: 8.6751\n",
      "Epoch 496/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 107.1410 - reconstruction_loss: 98.2295 - kl_loss: 8.9115\n",
      "Epoch 497/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.8974 - reconstruction_loss: 98.8791 - kl_loss: 9.0183\n",
      "Epoch 498/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 108.4895 - reconstruction_loss: 99.5181 - kl_loss: 8.9714\n",
      "Epoch 499/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 106.7757 - reconstruction_loss: 97.7397 - kl_loss: 9.0361\n",
      "Epoch 500/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 106.9004 - reconstruction_loss: 98.0056 - kl_loss: 8.8948\n",
      "Epoch 501/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 107.9499 - reconstruction_loss: 99.1132 - kl_loss: 8.8367\n",
      "Epoch 502/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.5347 - reconstruction_loss: 98.6055 - kl_loss: 8.9292\n",
      "Epoch 503/1000\n",
      "7/7 [==============================] - 0s 8ms/step - total_loss: 108.1021 - reconstruction_loss: 99.0550 - kl_loss: 9.0471\n",
      "Epoch 504/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.2926 - reconstruction_loss: 98.1766 - kl_loss: 9.1160\n",
      "Epoch 505/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 107.4797 - reconstruction_loss: 98.5146 - kl_loss: 8.9651\n",
      "Epoch 506/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.0235 - reconstruction_loss: 98.0663 - kl_loss: 8.9572\n",
      "Epoch 507/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 107.6832 - reconstruction_loss: 98.8886 - kl_loss: 8.7945\n",
      "Epoch 508/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 107.2585 - reconstruction_loss: 98.2994 - kl_loss: 8.9591\n",
      "Epoch 509/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 106.8531 - reconstruction_loss: 97.9800 - kl_loss: 8.8731\n",
      "Epoch 510/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.5077 - reconstruction_loss: 98.6829 - kl_loss: 8.8248\n",
      "Epoch 511/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.3283 - reconstruction_loss: 98.5352 - kl_loss: 8.7931\n",
      "Epoch 512/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.3653 - reconstruction_loss: 98.5245 - kl_loss: 8.8408\n",
      "Epoch 513/1000\n",
      "7/7 [==============================] - 0s 8ms/step - total_loss: 106.4875 - reconstruction_loss: 97.6286 - kl_loss: 8.8590\n",
      "Epoch 514/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 106.3952 - reconstruction_loss: 97.4730 - kl_loss: 8.9222\n",
      "Epoch 515/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.3281 - reconstruction_loss: 98.3592 - kl_loss: 8.9688\n",
      "Epoch 516/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 106.8923 - reconstruction_loss: 97.9381 - kl_loss: 8.9542\n",
      "Epoch 517/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 108.1151 - reconstruction_loss: 99.1679 - kl_loss: 8.9472\n",
      "Epoch 518/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 106.6593 - reconstruction_loss: 97.6228 - kl_loss: 9.0366\n",
      "Epoch 519/1000\n",
      "7/7 [==============================] - 0s 10ms/step - total_loss: 107.3110 - reconstruction_loss: 98.3062 - kl_loss: 9.0048\n",
      "Epoch 520/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.3494 - reconstruction_loss: 98.4131 - kl_loss: 8.9363\n",
      "Epoch 521/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.2103 - reconstruction_loss: 98.3588 - kl_loss: 8.8515\n",
      "Epoch 522/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 106.5057 - reconstruction_loss: 97.5616 - kl_loss: 8.9441\n",
      "Epoch 523/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 107.9205 - reconstruction_loss: 99.0631 - kl_loss: 8.8573\n",
      "Epoch 524/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 106.7839 - reconstruction_loss: 97.9369 - kl_loss: 8.8470\n",
      "Epoch 525/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 106.6585 - reconstruction_loss: 97.8569 - kl_loss: 8.8015\n",
      "Epoch 526/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 106.4481 - reconstruction_loss: 97.5640 - kl_loss: 8.8841\n",
      "Epoch 527/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 105.9033 - reconstruction_loss: 96.8884 - kl_loss: 9.0149\n",
      "Epoch 528/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 106.7640 - reconstruction_loss: 97.7020 - kl_loss: 9.0620\n",
      "Epoch 529/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 108.6071 - reconstruction_loss: 99.6975 - kl_loss: 8.9096\n",
      "Epoch 530/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 107.1275 - reconstruction_loss: 98.1656 - kl_loss: 8.9619\n",
      "Epoch 531/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 107.3130 - reconstruction_loss: 98.3566 - kl_loss: 8.9564\n",
      "Epoch 532/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 106.6475 - reconstruction_loss: 97.5671 - kl_loss: 9.0804\n",
      "Epoch 533/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.2324 - reconstruction_loss: 98.1047 - kl_loss: 9.1277\n",
      "Epoch 534/1000\n",
      "7/7 [==============================] - 0s 12ms/step - total_loss: 107.3234 - reconstruction_loss: 98.1968 - kl_loss: 9.1266\n",
      "Epoch 535/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 106.4515 - reconstruction_loss: 97.3718 - kl_loss: 9.0797\n",
      "Epoch 536/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 106.7047 - reconstruction_loss: 97.6916 - kl_loss: 9.0131\n",
      "Epoch 537/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 107.2820 - reconstruction_loss: 98.2503 - kl_loss: 9.0318\n",
      "Epoch 538/1000\n",
      "7/7 [==============================] - 0s 8ms/step - total_loss: 107.3287 - reconstruction_loss: 98.2650 - kl_loss: 9.0637\n",
      "Epoch 539/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 107.0608 - reconstruction_loss: 98.0319 - kl_loss: 9.0289\n",
      "Epoch 540/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 106.7945 - reconstruction_loss: 97.9458 - kl_loss: 8.8487\n",
      "Epoch 541/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 107.2681 - reconstruction_loss: 98.3466 - kl_loss: 8.9214\n",
      "Epoch 542/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.9672 - reconstruction_loss: 98.9641 - kl_loss: 9.0031\n",
      "Epoch 543/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.5984 - reconstruction_loss: 98.5226 - kl_loss: 9.0758\n",
      "Epoch 544/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.6405 - reconstruction_loss: 98.4992 - kl_loss: 9.1412\n",
      "Epoch 545/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 106.4579 - reconstruction_loss: 97.3109 - kl_loss: 9.1470\n",
      "Epoch 546/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.7927 - reconstruction_loss: 98.6582 - kl_loss: 9.1345\n",
      "Epoch 547/1000\n",
      "7/7 [==============================] - 0s 8ms/step - total_loss: 107.8855 - reconstruction_loss: 98.7929 - kl_loss: 9.0926\n",
      "Epoch 548/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.2667 - reconstruction_loss: 98.0179 - kl_loss: 9.2488\n",
      "Epoch 549/1000\n",
      "7/7 [==============================] - 0s 9ms/step - total_loss: 108.4217 - reconstruction_loss: 99.1669 - kl_loss: 9.2549\n",
      "Epoch 550/1000\n",
      "7/7 [==============================] - 0s 9ms/step - total_loss: 107.6637 - reconstruction_loss: 98.4557 - kl_loss: 9.2080\n",
      "Epoch 551/1000\n",
      "7/7 [==============================] - 0s 8ms/step - total_loss: 106.9949 - reconstruction_loss: 97.8288 - kl_loss: 9.1660\n",
      "Epoch 552/1000\n",
      "7/7 [==============================] - 0s 8ms/step - total_loss: 107.0693 - reconstruction_loss: 97.9513 - kl_loss: 9.1180\n",
      "Epoch 553/1000\n",
      "7/7 [==============================] - 0s 8ms/step - total_loss: 106.6551 - reconstruction_loss: 97.5755 - kl_loss: 9.0796\n",
      "Epoch 554/1000\n",
      "7/7 [==============================] - 0s 8ms/step - total_loss: 106.6456 - reconstruction_loss: 97.5366 - kl_loss: 9.1090\n",
      "Epoch 555/1000\n",
      "7/7 [==============================] - 0s 8ms/step - total_loss: 106.5519 - reconstruction_loss: 97.5577 - kl_loss: 8.9942\n",
      "Epoch 556/1000\n",
      "7/7 [==============================] - 0s 10ms/step - total_loss: 107.3694 - reconstruction_loss: 98.4614 - kl_loss: 8.9081\n",
      "Epoch 557/1000\n",
      "7/7 [==============================] - 0s 8ms/step - total_loss: 106.5667 - reconstruction_loss: 97.6344 - kl_loss: 8.9323\n",
      "Epoch 558/1000\n",
      "7/7 [==============================] - 0s 8ms/step - total_loss: 107.2340 - reconstruction_loss: 98.1910 - kl_loss: 9.0430\n",
      "Epoch 559/1000\n",
      "7/7 [==============================] - 0s 8ms/step - total_loss: 107.4834 - reconstruction_loss: 98.5485 - kl_loss: 8.9350\n",
      "Epoch 560/1000\n",
      "7/7 [==============================] - 0s 9ms/step - total_loss: 107.3690 - reconstruction_loss: 98.4504 - kl_loss: 8.9186\n",
      "Epoch 561/1000\n",
      "7/7 [==============================] - 0s 9ms/step - total_loss: 106.6447 - reconstruction_loss: 97.7198 - kl_loss: 8.9248\n",
      "Epoch 562/1000\n",
      "7/7 [==============================] - 0s 8ms/step - total_loss: 106.8959 - reconstruction_loss: 97.8708 - kl_loss: 9.0251\n",
      "Epoch 563/1000\n",
      "7/7 [==============================] - 0s 13ms/step - total_loss: 106.8514 - reconstruction_loss: 97.6864 - kl_loss: 9.1650\n",
      "Epoch 564/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 107.8268 - reconstruction_loss: 98.6010 - kl_loss: 9.2258\n",
      "Epoch 565/1000\n",
      "7/7 [==============================] - 0s 8ms/step - total_loss: 106.8884 - reconstruction_loss: 97.6732 - kl_loss: 9.2151\n",
      "Epoch 566/1000\n",
      "7/7 [==============================] - 0s 8ms/step - total_loss: 107.0603 - reconstruction_loss: 97.8388 - kl_loss: 9.2215\n",
      "Epoch 567/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 106.8342 - reconstruction_loss: 97.6905 - kl_loss: 9.1437\n",
      "Epoch 568/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 106.1200 - reconstruction_loss: 97.2443 - kl_loss: 8.8757\n",
      "Epoch 569/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 106.8356 - reconstruction_loss: 98.1055 - kl_loss: 8.7301\n",
      "Epoch 570/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 107.0369 - reconstruction_loss: 98.1414 - kl_loss: 8.8954\n",
      "Epoch 571/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 106.0110 - reconstruction_loss: 96.8567 - kl_loss: 9.1543\n",
      "Epoch 572/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 107.2664 - reconstruction_loss: 98.1935 - kl_loss: 9.0730\n",
      "Epoch 573/1000\n",
      "7/7 [==============================] - 0s 10ms/step - total_loss: 107.5781 - reconstruction_loss: 98.5042 - kl_loss: 9.0739\n",
      "Epoch 574/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 107.1723 - reconstruction_loss: 98.1288 - kl_loss: 9.0435\n",
      "Epoch 575/1000\n",
      "7/7 [==============================] - 0s 7ms/step - total_loss: 106.3150 - reconstruction_loss: 97.1986 - kl_loss: 9.1164\n",
      "Epoch 576/1000\n",
      "7/7 [==============================] - 0s 8ms/step - total_loss: 106.3760 - reconstruction_loss: 97.1168 - kl_loss: 9.2592\n",
      "Epoch 577/1000\n",
      "7/7 [==============================] - 0s 6ms/step - total_loss: 107.0208 - reconstruction_loss: 97.9259 - kl_loss: 9.0949\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'intermediate_layer_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m data \u001b[39m=\u001b[39m preprocessing(PATH_TO_DATA\u001b[39m/\u001b[39mfile)\n\u001b[0;32m     16\u001b[0m vae, intermediate_model \u001b[39m=\u001b[39m vae_fit(data,  K\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, known_variance\u001b[39m=\u001b[39m\u001b[39m1.\u001b[39m, latent_dim\u001b[39m=\u001b[39mnum_latent)\n\u001b[1;32m---> 17\u001b[0m save_output(data, vae, intermediate_model, file)\n",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m, in \u001b[0;36msave_output\u001b[1;34m(data, vae, intermediate_model, file)\u001b[0m\n\u001b[0;32m      6\u001b[0m z \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39mppf(prob)\n\u001b[0;32m      7\u001b[0m z \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrepeat(z[:, np\u001b[39m.\u001b[39mnewaxis], num_latent, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m y_list \u001b[39m=\u001b[39m intermediate_layer_model\u001b[39m.\u001b[39mpredict(z)\n\u001b[0;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(y_list)):\n\u001b[0;32m     12\u001b[0m     y \u001b[39m=\u001b[39m y_list[k]\u001b[39m.\u001b[39msqueeze()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'intermediate_layer_model' is not defined"
     ]
    }
   ],
   "source": [
    "num_latent = 5\n",
    "# %% List all files\n",
    "PATH_TO_DATA = Path(f\"{args.dir}/x/\")\n",
    "PATH_TO_FIT  = Path(f\"{args.dir}/vae_fit/\")\n",
    "\n",
    "files = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(PATH_TO_DATA):\n",
    "    files.extend(filenames)\n",
    "    break\n",
    "\n",
    "print(f\"\\n{len(files)} files found in  directory {args.dir}.\")\n",
    "# %% We warm up our model on the firstfew files. pretrain permutes the colums\n",
    "# fit!\n",
    "for file in files:\n",
    "    data = preprocessing(PATH_TO_DATA/file)\n",
    "    vae, intermediate_model = vae_fit(data,  K=5, known_variance=1., latent_dim=num_latent)\n",
    "    save_output(data, vae, intermediate_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "save_output(data, vae, intermediate_model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
